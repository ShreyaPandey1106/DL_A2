{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "5m68iwKheCgL"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "from torch.optim.swa_utils import AveragedModel, SWALR\n",
        "from torchvision import models, transforms\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from timm.data import Mixup, create_transform\n",
        "from timm.loss import LabelSmoothingCrossEntropy, SoftTargetCrossEntropy\n",
        "from torch.optim.lr_scheduler import OneCycleLR\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "mII45hpqdpTR"
      },
      "outputs": [],
      "source": [
        "class_to_superclass = {\n",
        "    **dict.fromkeys(range(0, 5), 0),   # aquatic mammals\n",
        "    **dict.fromkeys(range(5, 10), 1),  # fish\n",
        "    **dict.fromkeys(range(10, 15), 2),  # flowers\n",
        "    **dict.fromkeys(range(15, 20), 3),  # food containers\n",
        "    **dict.fromkeys(range(20, 25), 4),  # fruit and vegetables\n",
        "    **dict.fromkeys(range(25, 30), 5),  # household electrical devices\n",
        "    **dict.fromkeys(range(30, 35), 6),  # household furniture\n",
        "    **dict.fromkeys(range(35, 40), 7),  # insects\n",
        "    **dict.fromkeys(range(40, 45), 8),  # large carnivores\n",
        "    **dict.fromkeys(range(45, 50), 9),  # large man-made outdoor things\n",
        "    **dict.fromkeys(range(50, 55), 10), # large natural outdoor scenes\n",
        "    **dict.fromkeys(range(55, 60), 11), # large omnivores and herbivores\n",
        "    **dict.fromkeys(range(60, 65), 12), # medium-sized mammals\n",
        "    **dict.fromkeys(range(65, 70), 13), # non-insect invertebrates\n",
        "    **dict.fromkeys(range(70, 75), 14), # people\n",
        "    **dict.fromkeys(range(75, 80), 15), # reptiles\n",
        "    **dict.fromkeys(range(80, 85), 16), # small mammals\n",
        "    **dict.fromkeys(range(85, 90), 17), # trees\n",
        "    **dict.fromkeys(range(90, 95), 18), # vehicles 1\n",
        "    **dict.fromkeys(range(95, 100), 19) # vehicles 2\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "dC4PEW4udrJK"
      },
      "outputs": [],
      "source": [
        "superclass_to_group = {\n",
        "    2: 0, 17: 0, 4: 0,   # Plants/Parts of plants\n",
        "    18: 1, 19: 1,        # Vehicles\n",
        "    13: 2, 7: 2,         # Invertebrates\n",
        "    1: 3, 0: 3,          # Aquatic animals\n",
        "    8: 4, 11: 4,         # Large animals\n",
        "    9: 5, 5: 5, 6: 5, 3: 5,  # Man-made articles\n",
        "    14: 6,               # People\n",
        "    15: 7, 12: 7, 16: 7, # Normal Terrestrial Animals\n",
        "    10: 8                # Outdoor scenes\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "bFjt8-_5dyR1"
      },
      "outputs": [],
      "source": [
        "def get_superclass_and_group(label):\n",
        "    superclass = class_to_superclass[label]\n",
        "    group = superclass_to_group[superclass]\n",
        "    return superclass, group"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0-DzwOvJeMrx",
        "outputId": "a5470b57-0201-4a21-d8f2-901f20295dc5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet50-11ad3fa6.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-11ad3fa6.pth\n",
            "100%|██████████| 97.8M/97.8M [00:01<00:00, 75.7MB/s]\n"
          ]
        }
      ],
      "source": [
        "# Load Pre-trained ResNet\n",
        "# resnet = models.resnet50(weights=models.ResNet50_Weights.DEFAULT)\n",
        "model = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V2)\n",
        "\n",
        "# Freeze all layers initially\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# Unfreeze deeper layers (More trainable parameters)\n",
        "# for param in model.layer3.parameters():\n",
        "#     param.requires_grad = True\n",
        "# for param in model.layer4.parameters():\n",
        "#     param.requires_grad = True\n",
        "# for param in model.fc.parameters():\n",
        "#     param.requires_grad = True\n",
        "\n",
        "# Modify the Fully Connected Layer\n",
        "num_features = model.fc.in_features\n",
        "model.fc = nn.Sequential(\n",
        "    nn.Linear(num_features, 512),\n",
        "    nn.ReLU(),\n",
        "    nn.Dropout(0.5),\n",
        "    nn.Linear(512, 100)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "0U-_FSGXmFRX"
      },
      "outputs": [],
      "source": [
        "train_transform = create_transform(\n",
        "    input_size=224, is_training=True, auto_augment='rand-m9-mstd0.5-inc1'\n",
        ")\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CB4Pf2HAeVdv",
        "outputId": "28832bd1-8098-470d-9655-53859535f3d0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz to ./data/cifar-100-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 169M/169M [00:05<00:00, 30.2MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-100-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "trainset_full = torchvision.datasets.CIFAR100(root='./data', train=True, download=True, transform=train_transform) #Load the full dataset\n",
        "\n",
        "testset = torchvision.datasets.CIFAR100(root='./data', train=False, download=True, transform=test_transform)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oJeNQLuHfOwO",
        "outputId": "f33c3534-8f5d-4fbb-e5e5-450103e2a507"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ResNet(\n",
              "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (relu): ReLU(inplace=True)\n",
              "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "  (layer1): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (3): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (3): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (4): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (5): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (layer4): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  (fc): Sequential(\n",
              "    (0): Linear(in_features=2048, out_features=512, bias=True)\n",
              "    (1): ReLU()\n",
              "    (2): Dropout(p=0.5, inplace=False)\n",
              "    (3): Linear(in_features=512, out_features=100, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "sPk8D8f-lygQ"
      },
      "outputs": [],
      "source": [
        "mixup = Mixup(mixup_alpha=0.2, cutmix_alpha=0.3, label_smoothing=0.1, num_classes=100)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "KBjZsV3enCRf"
      },
      "outputs": [],
      "source": [
        "results = {}\n",
        "def train_and_eval(split_size, criterion):\n",
        "    train_size = int(split_size * len(trainset_full))\n",
        "    val_size = len(trainset_full) - train_size\n",
        "    trainset, valset = random_split(trainset_full, [train_size, val_size])\n",
        "\n",
        "    trainloader = DataLoader(trainset, batch_size=128, shuffle=True, num_workers=2, pin_memory=True)\n",
        "    valloader = DataLoader(valset, batch_size=128, shuffle=False, num_workers=2, pin_memory=True)\n",
        "    testloader = DataLoader(testset, batch_size=128, shuffle=False, num_workers=2, pin_memory=True)\n",
        "\n",
        "    num_epochs = 30\n",
        "    best_accuracy = 0.0\n",
        "\n",
        "    optimizer = optim.AdamW(model.parameters(), lr=0.0005, weight_decay=5e-4)\n",
        "    scheduler = OneCycleLR(optimizer, max_lr=0.0005, epochs=num_epochs, steps_per_epoch=len(trainloader), pct_start=0.1)\n",
        "    scaler = torch.amp.GradScaler('cuda')\n",
        "    swa_model = AveragedModel(model)\n",
        "    swa_scheduler = SWALR(optimizer, swa_lr=0.0001)\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        correct_class, correct_superclass, correct_group, total = 0, 0, 0, 0\n",
        "\n",
        "        for images, labels in trainloader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "            if np.random.rand() < 0.5:\n",
        "\n",
        "             images, labels = mixup(images, labels)   # Get mixed image and target\n",
        "             if labels.shape[0] != images.shape[0]:  # Ensure batch size consistency\n",
        "                 labels = labels[:images.shape[0], :]\n",
        "             true_classes =labels.argmax(dim=1)\n",
        "\n",
        "            else:\n",
        "             true_classes = labels\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            with torch.autocast('cuda'):\n",
        "                outputs = model(images)\n",
        "                if labels.dim() == 2:\n",
        "                     loss = SoftTargetCrossEntropy()(outputs, labels)\n",
        "                else:\n",
        "                     loss = criterion(outputs, labels.long())\n",
        "            scaler.scale(loss).backward()\n",
        "            scaler.unscale_(optimizer)\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            predicted = outputs.argmax(dim=1)\n",
        "\n",
        "            correct_class += (predicted == true_classes).sum().item()\n",
        "            superclasses, groups = zip(*[get_superclass_and_group(tc.item()) for tc in true_classes])\n",
        "            predicted_superclasses = [class_to_superclass[p.item()] for p in predicted]\n",
        "            predicted_groups = [superclass_to_group[sc] for sc in predicted_superclasses]\n",
        "\n",
        "            correct_superclass += sum(ps == sc for ps, sc in zip(predicted_superclasses, superclasses))\n",
        "            correct_group += sum(pg == g for pg, g in zip(predicted_groups, groups))\n",
        "            total += images.size(0)\n",
        "\n",
        "        epoch_loss = running_loss / len(trainloader)\n",
        "        # if epoch%5==0:\n",
        "        print(f\"Epoch [{epoch+1}/{num_epochs}]\\nLoss: {epoch_loss:.4f}, Class Acc: {100 * correct_class / total:.2f}%, \"\n",
        "              f\"Superclass Acc: {100 * correct_superclass / total:.2f}%, Group Acc: {100 * correct_group / total:.2f}%\")\n",
        "\n",
        "        # Validation\n",
        "        model.eval()\n",
        "        val_loss, val_correct_class, val_correct_superclass, val_correct_group, val_total = 0, 0, 0, 0, 0\n",
        "        with torch.no_grad():\n",
        "            for images, labels in valloader:\n",
        "                images, labels = images.to(device), labels.to(device)\n",
        "                outputs = model(images)\n",
        "                loss = criterion(outputs, labels.long())\n",
        "                val_loss += loss.item()\n",
        "\n",
        "                predicted = outputs.argmax(dim=1)\n",
        "                superclasses, groups = zip(*[get_superclass_and_group(l.item()) for l in labels])\n",
        "                predicted_superclasses = [class_to_superclass[p.item()] for p in predicted]\n",
        "                predicted_groups = [superclass_to_group[sc] for sc in predicted_superclasses]\n",
        "\n",
        "                val_correct_class += (predicted == labels).sum().item()\n",
        "                val_correct_superclass += sum(ps == sc for ps, sc in zip(predicted_superclasses, superclasses))\n",
        "                val_correct_group += sum(pg == g for pg, g in zip(predicted_groups, groups))\n",
        "                val_total += labels.size(0)\n",
        "\n",
        "        # if epoch%4==0:\n",
        "        print(f\"Val Loss: {val_loss / len(valloader):.4f}, Class Acc: {100 * val_correct_class / val_total:.2f}%, \"\n",
        "              f\"Superclass Acc: {100 * val_correct_superclass / val_total:.2f}%, Group Acc: {100 * val_correct_group / val_total:.2f}%\")\n",
        "\n",
        "        scheduler.step()\n",
        "        if val_correct_class / val_total > best_accuracy:\n",
        "            best_accuracy = val_correct_class / val_total\n",
        "            torch.save(model.state_dict(), 'best_model.pth')\n",
        "\n",
        "        if epoch >= 20:\n",
        "            swa_model.update_parameters(model)\n",
        "            swa_scheduler.step()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        if any(isinstance(layer, nn.BatchNorm2d) for layer in model.modules()):\n",
        "               swa_model.cpu()\n",
        "               torch.optim.swa_utils.update_bn(trainloader, swa_model)\n",
        "               swa_model.to(device)\n",
        "    torch.save(swa_model.state_dict(), 'swa_model.pth')\n",
        "    print(\"SWA Model Saved!\")\n",
        "    swa_model.to(device)\n",
        "\n",
        "    # Testing with SWA Model\n",
        "    swa_model.eval()\n",
        "    y_true, y_pred, y_true_superclass, y_pred_superclass, y_true_group, y_pred_group = [], [], [], [], [], []\n",
        "    with torch.no_grad():\n",
        "        for images, labels in testloader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = torch.stack([swa_model(images) for _ in range(5)]).mean(0)\n",
        "            predicted = outputs.argmax(dim=1).cpu().numpy()\n",
        "            labels = labels.cpu().numpy()\n",
        "\n",
        "            for true_class, predicted_class in zip(labels, predicted):\n",
        "                superclass, group = get_superclass_and_group(true_class)\n",
        "                predicted_superclass = class_to_superclass[predicted_class]\n",
        "                predicted_group = superclass_to_group[predicted_superclass]\n",
        "\n",
        "                y_true.append(true_class)\n",
        "                y_pred.append(predicted_class)\n",
        "                y_true_superclass.append(superclass)\n",
        "                y_pred_superclass.append(predicted_superclass)\n",
        "                y_true_group.append(group)\n",
        "                y_pred_group.append(predicted_group)\n",
        "    cm_class = confusion_matrix(y_true, y_pred)\n",
        "    cm_superclass = confusion_matrix(y_true_superclass, y_pred_superclass)\n",
        "    cm_group = confusion_matrix(y_true_group, y_pred_group)\n",
        "    test_accuracy_class= round(accuracy_score(y_true, y_pred),4)\n",
        "    test_accuracy_superclass = round(accuracy_score(y_true_superclass, y_pred_superclass),4)\n",
        "    test_accuracy_group = round(accuracy_score(y_true_group, y_pred_group),4)\n",
        "    print(f\"Test Accuracy (Class): {test_accuracy_class:.4f}\")\n",
        "    print(f\"Test Accuracy (Superclass): {test_accuracy_superclass:.4f}\")\n",
        "    print(f\"Test Accuracy (Group): {test_accuracy_group:.4f}\")\n",
        "    results[train_size]= {\n",
        "        'cm_class': cm_class,\n",
        "        'cm_superclass': cm_superclass,\n",
        "        'cm_group': cm_group,\n",
        "        'test_accuracy_class': test_accuracy_class,\n",
        "        'test_accuracy_superclass': test_accuracy_superclass,\n",
        "        'test_accuracy_group': test_accuracy_group,\n",
        "        'best_accuracy': best_accuracy\n",
        "    }\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gzu15JaNhgSs",
        "outputId": "8f20f1ba-b7c6-430a-ccd8-8ff496918fe1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Split size 70 - 30\n",
            "Epoch [1/30]\n",
            "Loss: 4.5990, Class Acc: 1.42%, Superclass Acc: 5.26%, Group Acc: 12.97%\n",
            "Val Loss: 4.5802, Class Acc: 3.86%, Superclass Acc: 7.21%, Group Acc: 15.41%\n",
            "Epoch [2/30]\n",
            "Loss: 4.5687, Class Acc: 3.34%, Superclass Acc: 6.99%, Group Acc: 14.28%\n",
            "Val Loss: 4.5430, Class Acc: 7.74%, Superclass Acc: 10.86%, Group Acc: 17.87%\n",
            "Epoch [3/30]\n",
            "Loss: 4.5267, Class Acc: 5.39%, Superclass Acc: 9.00%, Group Acc: 16.21%\n",
            "Val Loss: 4.4823, Class Acc: 10.81%, Superclass Acc: 14.06%, Group Acc: 21.33%\n",
            "Epoch [4/30]\n",
            "Loss: 4.4719, Class Acc: 7.37%, Superclass Acc: 10.83%, Group Acc: 17.98%\n",
            "Val Loss: 4.4214, Class Acc: 13.37%, Superclass Acc: 16.67%, Group Acc: 23.45%\n",
            "Epoch [5/30]\n",
            "Loss: 4.4163, Class Acc: 8.50%, Superclass Acc: 12.03%, Group Acc: 19.32%\n",
            "Val Loss: 4.3499, Class Acc: 13.84%, Superclass Acc: 17.40%, Group Acc: 23.87%\n",
            "Epoch [6/30]\n",
            "Loss: 4.3606, Class Acc: 9.29%, Superclass Acc: 12.69%, Group Acc: 19.49%\n",
            "Val Loss: 4.2785, Class Acc: 14.52%, Superclass Acc: 17.71%, Group Acc: 24.35%\n",
            "Epoch [7/30]\n",
            "Loss: 4.3155, Class Acc: 9.83%, Superclass Acc: 13.36%, Group Acc: 20.25%\n",
            "Val Loss: 4.2371, Class Acc: 15.65%, Superclass Acc: 18.75%, Group Acc: 25.01%\n",
            "Epoch [8/30]\n",
            "Loss: 4.2650, Class Acc: 10.42%, Superclass Acc: 13.84%, Group Acc: 20.81%\n",
            "Val Loss: 4.1935, Class Acc: 15.93%, Superclass Acc: 18.93%, Group Acc: 25.09%\n",
            "Epoch [9/30]\n",
            "Loss: 4.2287, Class Acc: 11.13%, Superclass Acc: 14.43%, Group Acc: 21.20%\n",
            "Val Loss: 4.1592, Class Acc: 16.83%, Superclass Acc: 19.87%, Group Acc: 26.15%\n",
            "Epoch [10/30]\n",
            "Loss: 4.1895, Class Acc: 11.35%, Superclass Acc: 14.61%, Group Acc: 21.47%\n",
            "Val Loss: 4.0867, Class Acc: 16.80%, Superclass Acc: 19.95%, Group Acc: 26.07%\n",
            "Epoch [11/30]\n",
            "Loss: 4.1573, Class Acc: 11.95%, Superclass Acc: 15.13%, Group Acc: 22.03%\n",
            "Val Loss: 4.0823, Class Acc: 17.60%, Superclass Acc: 20.75%, Group Acc: 26.77%\n",
            "Epoch [12/30]\n",
            "Loss: 4.1420, Class Acc: 12.10%, Superclass Acc: 15.43%, Group Acc: 21.94%\n",
            "Val Loss: 4.0159, Class Acc: 17.76%, Superclass Acc: 20.84%, Group Acc: 27.03%\n",
            "Epoch [13/30]\n",
            "Loss: 4.1003, Class Acc: 12.91%, Superclass Acc: 16.16%, Group Acc: 22.77%\n"
          ]
        }
      ],
      "source": [
        "train_test_splits = {0.7,0.8,0.9}\n",
        "\n",
        "for split_size in train_test_splits:\n",
        "  print(f\"\\n\\nSplit size {int(split_size*100)} - {int(100-split_size*100)}\")\n",
        "  criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
        "  train_and_eval(split_size, criterion)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6ILxQTT9cfJ5"
      },
      "outputs": [],
      "source": [
        "\n",
        "print(\"\\n--- Final Results ---\")\n",
        "for train_size, metrics in results.items():\n",
        "    print(f\"\\nTrain Size: {train_size}\")\n",
        "    print(f\"Test Accuracy (Class): {metrics['test_accuracy_class']:.4f}\")\n",
        "    print(f\"Test Accuracy (Superclass): {metrics['test_accuracy_superclass']:.4f}\")\n",
        "    print(f\"Test Accuracy (Group): {metrics['test_accuracy_group']:.4f}\")\n",
        "    print(f\"Best Accuracy: {metrics['best_accuracy']:.4f}\")\n",
        "\n",
        "    # Function to plot confusion matrix\n",
        "    def plot_confusion_matrix(cm, title):\n",
        "        plt.figure(figsize=(8, 6))\n",
        "        sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", annot_kws={\"size\": 10})\n",
        "        plt.xticks(rotation=45, ha=\"right\")\n",
        "        plt.title(f\"{title} (Train Size: {train_size})\", fontsize=14)\n",
        "        plt.xlabel(\"Predicted Label\", fontsize=12)\n",
        "        plt.ylabel(\"True Label\", fontsize=12)\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "    # Plot confusion matrices\n",
        "    plot_confusion_matrix(metrics['cm_class'], \"Confusion Matrix (Class)\")\n",
        "    plot_confusion_matrix(metrics['cm_superclass'], \"Confusion Matrix (Superclass)\")\n",
        "    plot_confusion_matrix(metrics['cm_group'], \"Confusion Matrix (Group)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Cv-DTEYHApH"
      },
      "source": [
        "# Bonus Task"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pkJrRak5HHXS"
      },
      "outputs": [],
      "source": [
        "class SeverityWeightedLoss(nn.Module):\n",
        "    def __init__(self, base_loss=nn.CrossEntropyLoss()):\n",
        "        super().__init__()\n",
        "        self.base_loss = base_loss\n",
        "\n",
        "    def forward(self, outputs, true_classes):\n",
        "        predicted = outputs.argmax(dim=1)\n",
        "\n",
        "        # Compute severity levels\n",
        "        superclasses, groups = zip(*[get_superclass_and_group(tc.item()) for tc in true_classes])\n",
        "        predicted_superclasses = [class_to_superclass[p.item()] for p in predicted]\n",
        "        predicted_groups = [superclass_to_group[sc] for sc in predicted_superclasses]\n",
        "\n",
        "        severity = torch.tensor(\n",
        "            [0 if p == t else\n",
        "             1 if ps == sc else\n",
        "             2 if pg == g else\n",
        "             3 for p, t, ps, sc, pg, g in zip(predicted, true_classes, predicted_superclasses, superclasses, predicted_groups, groups)],\n",
        "            dtype=torch.float32,\n",
        "            device=device\n",
        "        )\n",
        "\n",
        "        # Define severity-based weight (higher severity = higher penalty)\n",
        "        severity_weights = 1 + (severity / 3)  # Normalized to [1, 2]\n",
        "\n",
        "        # Compute weighted loss\n",
        "        base_loss = self.base_loss(outputs, true_classes.long())\n",
        "        weighted_loss = (base_loss * severity_weights).mean()\n",
        "        return weighted_loss\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "45EUfyBQG6ds"
      },
      "outputs": [],
      "source": [
        "def bonus_train_and_eval(split_size):\n",
        "    criterion = SeverityWeightedLoss()\n",
        "\n",
        "    train_size = int(split_size * len(trainset_full))\n",
        "    val_size = len(trainset_full) - train_size\n",
        "    trainset, valset = random_split(trainset_full, [train_size, val_size])\n",
        "\n",
        "    trainloader = DataLoader(trainset, batch_size=128, shuffle=True, num_workers=2, pin_memory=True)\n",
        "    valloader = DataLoader(valset, batch_size=128, shuffle=False, num_workers=2, pin_memory=True)\n",
        "    testloader = DataLoader(testset, batch_size=128, shuffle=False, num_workers=2, pin_memory=True)\n",
        "\n",
        "    num_epochs = 30\n",
        "    best_accuracy = 0.0\n",
        "\n",
        "    optimizer = optim.AdamW(model.parameters(), lr=0.0005, weight_decay=5e-4)\n",
        "    scheduler = OneCycleLR(optimizer, max_lr=0.0005, epochs=num_epochs, steps_per_epoch=len(trainloader), pct_start=0.1)\n",
        "    scaler = torch.amp.GradScaler('cuda')\n",
        "    swa_model = AveragedModel(model)\n",
        "    swa_scheduler = SWALR(optimizer, swa_lr=0.0001)\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        correct_class, correct_superclass, correct_group, total = 0, 0, 0, 0\n",
        "\n",
        "        for images, labels in trainloader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "            if np.random.rand() < 0.5:\n",
        "                images, labels = mixup(images, labels)\n",
        "                if labels.shape[0] != images.shape[0]:\n",
        "                    labels = labels[:images.shape[0], :]\n",
        "                true_classes = labels.argmax(dim=1)\n",
        "            else:\n",
        "                true_classes = labels\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            with torch.autocast('cuda'):\n",
        "                outputs = model(images)\n",
        "                loss = criterion(outputs, true_classes)  # ✅ Training uses severity-based loss\n",
        "\n",
        "            scaler.scale(loss).backward()\n",
        "            scaler.unscale_(optimizer)\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            predicted = outputs.argmax(dim=1)\n",
        "\n",
        "            correct_class += (predicted == true_classes).sum().item()\n",
        "            superclasses, groups = zip(*[get_superclass_and_group(tc.item()) for tc in true_classes])\n",
        "            predicted_superclasses = [class_to_superclass[p.item()] for p in predicted]\n",
        "            predicted_groups = [superclass_to_group[sc] for sc in predicted_superclasses]\n",
        "\n",
        "            correct_superclass += sum(ps == sc for ps, sc in zip(predicted_superclasses, superclasses))\n",
        "            correct_group += sum(pg == g for pg, g in zip(predicted_groups, groups))\n",
        "            total += images.size(0)\n",
        "\n",
        "        epoch_loss = running_loss / len(trainloader)\n",
        "        if epoch%5==0:\n",
        "         print(f\"Epoch [{epoch+1}/{num_epochs}]\\nLoss: {epoch_loss:.4f}, Class Acc: {100 * correct_class / total:.2f}%, \"\n",
        "              f\"Superclass Acc: {100 * correct_superclass / total:.2f}%, Group Acc: {100 * correct_group / total:.2f}%\")\n",
        "\n",
        "        # Validation\n",
        "        model.eval()\n",
        "        val_loss, val_correct_class, val_correct_superclass, val_correct_group, val_total = 0, 0, 0, 0, 0\n",
        "        with torch.no_grad():\n",
        "            for images, labels in valloader:\n",
        "                images, labels = images.to(device), labels.to(device)\n",
        "                outputs = model(images)\n",
        "                loss = criterion(outputs, labels.long())  # ✅ Severity loss used in validation\n",
        "                val_loss += loss.item()\n",
        "\n",
        "                predicted = outputs.argmax(dim=1)\n",
        "                superclasses, groups = zip(*[get_superclass_and_group(l.item()) for l in labels])\n",
        "                predicted_superclasses = [class_to_superclass[p.item()] for p in predicted]\n",
        "                predicted_groups = [superclass_to_group[sc] for sc in predicted_superclasses]\n",
        "\n",
        "                val_correct_class += (predicted == labels).sum().item()\n",
        "                val_correct_superclass += sum(ps == sc for ps, sc in zip(predicted_superclasses, superclasses))\n",
        "                val_correct_group += sum(pg == g for pg, g in zip(predicted_groups, groups))\n",
        "                val_total += labels.size(0)\n",
        "        if epoch%4==0:\n",
        "           print(f\"Val Loss: {val_loss / len(valloader):.4f}, Class Acc: {100 * val_correct_class / val_total:.2f}%, \"\n",
        "              f\"Superclass Acc: {100 * val_correct_superclass / val_total:.2f}%, Group Acc: {100 * val_correct_group / val_total:.2f}%\")\n",
        "\n",
        "        scheduler.step()\n",
        "        if val_correct_class / val_total > best_accuracy:\n",
        "            best_accuracy = val_correct_class / val_total\n",
        "            torch.save(model.state_dict(), 'best_model.pth')\n",
        "\n",
        "        if epoch >= 20:\n",
        "            swa_model.update_parameters(model)\n",
        "            swa_scheduler.step()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        if any(isinstance(layer, nn.BatchNorm2d) for layer in model.modules()):\n",
        "               swa_model.cpu()\n",
        "               torch.optim.swa_utils.update_bn(trainloader, swa_model)\n",
        "               swa_model.to(device)\n",
        "    torch.save(swa_model.state_dict(), 'swa_model.pth')\n",
        "    print(\"SWA Model Saved!\")\n",
        "    swa_model.to(device)\n",
        "\n",
        "    # Testing with SWA Model\n",
        "    swa_model.eval()\n",
        "    y_true, y_pred, y_true_superclass, y_pred_superclass, y_true_group, y_pred_group = [], [], [], [], [], []\n",
        "    with torch.no_grad():\n",
        "        for images, labels in testloader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = torch.stack([swa_model(images) for _ in range(5)]).mean(0)\n",
        "            predicted = outputs.argmax(dim=1).cpu().numpy()\n",
        "            labels = labels.cpu().numpy()\n",
        "\n",
        "            for true_class, predicted_class in zip(labels, predicted):\n",
        "                superclass, group = get_superclass_and_group(true_class)\n",
        "                predicted_superclass = class_to_superclass[predicted_class]\n",
        "                predicted_group = superclass_to_group[predicted_superclass]\n",
        "\n",
        "                y_true.append(true_class)\n",
        "                y_pred.append(predicted_class)\n",
        "                y_true_superclass.append(superclass)\n",
        "                y_pred_superclass.append(predicted_superclass)\n",
        "                y_true_group.append(group)\n",
        "                y_pred_group.append(predicted_group)\n",
        "\n",
        "    cm_class = confusion_matrix(y_true, y_pred)\n",
        "    cm_superclass = confusion_matrix(y_true_superclass, y_pred_superclass)\n",
        "    cm_group = confusion_matrix(y_true_group, y_pred_group)\n",
        "    test_accuracy_class= round(accuracy_score(y_true, y_pred),4)\n",
        "    test_accuracy_superclass = round(accuracy_score(y_true_superclass, y_pred_superclass),4)\n",
        "    test_accuracy_group = round(accuracy_score(y_true_group, y_pred_group),4)\n",
        "    results[train_size]= {\n",
        "        'cm_class': cm_class,\n",
        "        'cm_superclass': cm_superclass,\n",
        "        'cm_group': cm_group,\n",
        "        'test_accuracy_class': test_accuracy_class,\n",
        "        'test_accuracy_superclass': test_accuracy_superclass,\n",
        "        'test_accuracy_group': test_accuracy_group,\n",
        "        'best_accuracy': best_accuracy\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lDhOzntTHUOt"
      },
      "outputs": [],
      "source": [
        "train_test_splits = {0.7,0.8,0.9}\n",
        "\n",
        "for split_size in train_test_splits:\n",
        "  print(f\"\\n\\nSplit size {int(split_size*100)} - {int(100-split_size*100)}\")\n",
        "  bonus_train_and_eval(split_size)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3c1SngZugLHO"
      },
      "outputs": [],
      "source": [
        "\n",
        "print(\"\\n--- Final Results ---\")\n",
        "for train_size, metrics in results.items():\n",
        "    print(f\"\\nTrain Size: {train_size}\")\n",
        "    print(f\"Test Accuracy (Class): {metrics['test_accuracy_class']:.4f}\")\n",
        "    print(f\"Test Accuracy (Superclass): {metrics['test_accuracy_superclass']:.4f}\")\n",
        "    print(f\"Test Accuracy (Group): {metrics['test_accuracy_group']:.4f}\")\n",
        "    print(f\"Best Accuracy: {metrics['best_accuracy']:.4f}\")\n",
        "\n",
        "    # Function to plot confusion matrix\n",
        "    def plot_confusion_matrix(cm, title):\n",
        "        plt.figure(figsize=(8, 6))\n",
        "        sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", annot_kws={\"size\": 10})\n",
        "        plt.xticks(rotation=45, ha=\"right\")\n",
        "        plt.title(f\"{title} (Train Size: {train_size})\", fontsize=14)\n",
        "        plt.xlabel(\"Predicted Label\", fontsize=12)\n",
        "        plt.ylabel(\"True Label\", fontsize=12)\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "    # Plot confusion matrices\n",
        "    plot_confusion_matrix(metrics['cm_class'], \"Confusion Matrix (Class)\")\n",
        "    plot_confusion_matrix(metrics['cm_superclass'], \"Confusion Matrix (Superclass)\")\n",
        "    plot_confusion_matrix(metrics['cm_group'], \"Confusion Matrix (Group)\")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}